{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###To run it directly on huggingface interface\n",
        "from llama import BasicModelRunner\n",
        "\n",
        "model = BasicModelRunner(\"EleutherAI/pythia-410m\")\n",
        "\n",
        "model.load_data_from_jsonlines(\"lamini_docs.jsonl\", input_key=\"question\", output_key=\"answer\")\n",
        "\n",
        "model.train(is_public=True)"
      ],
      "metadata": {
        "id": "RS4Bsx_7GSK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lamini"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2tT758uG3wL",
        "outputId": "8db112aa-e5da-4b03-a4c6-5b35e560842e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lamini in /usr/local/lib/python3.10/dist-packages (2.1.7)\n",
            "Requirement already satisfied: lamini-configuration[yaml] in /usr/local/lib/python3.10/dist-packages (from lamini) (0.8.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from lamini) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from lamini) (4.66.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lamini) (1.25.2)\n",
            "Requirement already satisfied: jsonlines in /usr/local/lib/python3.10/dist-packages (from lamini) (4.0.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from lamini) (2.0.3)\n",
            "Requirement already satisfied: azure-storage-blob in /usr/local/lib/python3.10/dist-packages (from lamini) (12.19.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from lamini) (1.2.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from lamini) (3.9.3)\n",
            "Requirement already satisfied: lm-eval==0.4.2 in /usr/local/lib/python3.10/dist-packages (from lamini) (0.4.2)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from lm-eval==0.4.2->lamini) (0.29.2)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (from lm-eval==0.4.2->lamini) (0.4.1)\n",
            "Requirement already satisfied: datasets>=2.16.0 in /usr/local/lib/python3.10/dist-packages (from lm-eval==0.4.2->lamini) (2.18.0)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.10/dist-packages (from lm-eval==0.4.2->lamini) (2.10.0)\n",
            "Requirement already satisfied: peft>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from lm-eval==0.4.2->lamini) (0.10.0)\n",
            "Requirement already satisfied: pybind11>=2.6.2 in /usr/local/lib/python3.10/dist-packages (from lm-eval==0.4.2->lamini) (2.12.0)\n",
            "Requirement already satisfied: pytablewriter in /usr/local/lib/python3.10/dist-packages (from lm-eval==0.4.2->lamini) (1.2.0)\n",
            "Requirement already satisfied: rouge-score>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from lm-eval==0.4.2->lamini) (0.1.2)\n",
            "Requirement already satisfied: sacrebleu>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from lm-eval==0.4.2->lamini) (2.4.2)\n",
            "Requirement already satisfied: sqlitedict in /usr/local/lib/python3.10/dist-packages (from lm-eval==0.4.2->lamini) (2.1.0)\n",
            "Requirement already satisfied: torch>=1.8 in /usr/local/lib/python3.10/dist-packages (from lm-eval==0.4.2->lamini) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm-multiprocess in /usr/local/lib/python3.10/dist-packages (from lm-eval==0.4.2->lamini) (0.0.11)\n",
            "Requirement already satisfied: transformers>=4.1 in /usr/local/lib/python3.10/dist-packages (from lm-eval==0.4.2->lamini) (4.32.1)\n",
            "Requirement already satisfied: zstandard in /usr/local/lib/python3.10/dist-packages (from lm-eval==0.4.2->lamini) (0.22.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from lm-eval==0.4.2->lamini) (0.3.8)\n",
            "Requirement already satisfied: word2number in /usr/local/lib/python3.10/dist-packages (from lm-eval==0.4.2->lamini) (1.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from lm-eval==0.4.2->lamini) (10.1.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lamini) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lamini) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lamini) (3.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->lamini) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->lamini) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->lamini) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->lamini) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->lamini) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->lamini) (4.0.3)\n",
            "Requirement already satisfied: azure-core<2.0.0,>=1.28.0 in /usr/local/lib/python3.10/dist-packages (from azure-storage-blob->lamini) (1.30.1)\n",
            "Requirement already satisfied: cryptography>=2.1.4 in /usr/local/lib/python3.10/dist-packages (from azure-storage-blob->lamini) (42.0.5)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from azure-storage-blob->lamini) (4.11.0)\n",
            "Requirement already satisfied: isodate>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from azure-storage-blob->lamini) (0.6.1)\n",
            "Requirement already satisfied: pyyaml<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from lamini-configuration[yaml]->lamini) (6.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->lamini) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->lamini) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->lamini) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->lamini) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->lamini) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->lamini) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->lamini) (2024.2.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->lm-eval==0.4.2->lamini) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->lm-eval==0.4.2->lamini) (5.9.5)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->lm-eval==0.4.2->lamini) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->lm-eval==0.4.2->lamini) (0.4.2)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from azure-core<2.0.0,>=1.28.0->azure-storage-blob->lamini) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=2.1.4->azure-storage-blob->lamini) (1.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm-eval==0.4.2->lamini) (3.13.4)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm-eval==0.4.2->lamini) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm-eval==0.4.2->lamini) (0.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm-eval==0.4.2->lamini) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm-eval==0.4.2->lamini) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm-eval==0.4.2->lamini) (2023.6.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate->lm-eval==0.4.2->lamini) (0.18.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score>=0.0.4->lm-eval==0.4.2->lamini) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score>=0.0.4->lm-eval==0.4.2->lamini) (3.8.1)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm-eval==0.4.2->lamini) (2.8.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm-eval==0.4.2->lamini) (2023.12.25)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm-eval==0.4.2->lamini) (0.9.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm-eval==0.4.2->lamini) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm-eval==0.4.2->lamini) (4.9.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm-eval==0.4.2->lamini) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm-eval==0.4.2->lamini) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm-eval==0.4.2->lamini) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm-eval==0.4.2->lamini) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm-eval==0.4.2->lamini) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm-eval==0.4.2->lamini) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm-eval==0.4.2->lamini) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm-eval==0.4.2->lamini) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm-eval==0.4.2->lamini) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm-eval==0.4.2->lamini) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm-eval==0.4.2->lamini) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm-eval==0.4.2->lamini) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm-eval==0.4.2->lamini) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm-eval==0.4.2->lamini) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm-eval==0.4.2->lamini) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8->lm-eval==0.4.2->lamini) (12.4.127)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.1->lm-eval==0.4.2->lamini) (0.13.3)\n",
            "Requirement already satisfied: setuptools>=38.3.0 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm-eval==0.4.2->lamini) (67.7.2)\n",
            "Requirement already satisfied: DataProperty<2,>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm-eval==0.4.2->lamini) (1.0.1)\n",
            "Requirement already satisfied: mbstrdecoder<2,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm-eval==0.4.2->lamini) (1.1.3)\n",
            "Requirement already satisfied: pathvalidate<4,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm-eval==0.4.2->lamini) (3.2.0)\n",
            "Requirement already satisfied: tabledata<2,>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm-eval==0.4.2->lamini) (1.3.3)\n",
            "Requirement already satisfied: tcolorpy<1,>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm-eval==0.4.2->lamini) (0.1.4)\n",
            "Requirement already satisfied: typepy[datetime]<2,>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm-eval==0.4.2->lamini) (1.3.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob->lamini) (2.22)\n",
            "Requirement already satisfied: chardet<6,>=3.0.4 in /usr/local/lib/python3.10/dist-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm-eval==0.4.2->lamini) (5.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8->lm-eval==0.4.2->lamini) (2.1.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score>=0.0.4->lm-eval==0.4.2->lamini) (8.1.7)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8->lm-eval==0.4.2->lamini) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "1AvMsFa-GJyp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import lamini\n",
        "\n",
        "lamini.api_url = os.getenv(\"POWERML__PRODUCTION__URL\")\n",
        "lamini.api_key = \"Get api Key"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets\n",
        "import tempfile\n",
        "import logging\n",
        "import random\n",
        "import config\n",
        "import os\n",
        "import yaml\n",
        "import time\n",
        "import torch\n",
        "import transformers\n",
        "import pandas as pd\n",
        "import jsonlines\n",
        "\n",
        "from utilities import *\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForCausalLM\n",
        "from transformers import TrainingArguments\n",
        "from transformers import AutoModelForCausalLM\n",
        "from llama import BasicModelRunner\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "global_config = None"
      ],
      "metadata": {
        "id": "KLk_f-pxGaBV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name = \"lamini_docs.jsonl\"\n",
        "dataset_path = f\"/content/{dataset_name}\"\n",
        "use_hf = False"
      ],
      "metadata": {
        "id": "Udg3Hl9VHts-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"lamini/lamini_docs\"\n",
        "use_hf = True"
      ],
      "metadata": {
        "id": "uk1tuJtkH5fK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"EleutherAI/pythia-70m\""
      ],
      "metadata": {
        "id": "zduBMCfhH8lT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_config = {\n",
        "    \"model\": {\n",
        "        \"pretrained_name\": model_name,\n",
        "        \"max_length\" : 2048\n",
        "    },\n",
        "    \"datasets\": {\n",
        "        \"use_hf\": use_hf,\n",
        "        \"path\": dataset_path\n",
        "    },\n",
        "    \"verbose\": True\n",
        "}"
      ],
      "metadata": {
        "id": "q0BZXy1_H_GV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "train_dataset, test_dataset = tokenize_and_split_data(training_config, tokenizer)\n",
        "\n",
        "print(train_dataset)\n",
        "print(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkrKmXsbIBPR",
        "outputId": "313c3eeb-2f04-44af-e287-2fb347e5d3d7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "DEBUG:utilities:Config: datasets.path: lamini/lamini_docs\n",
            "datasets.use_hf: true\n",
            "model.max_length: 2048\n",
            "model.pretrained_name: EleutherAI/pythia-70m\n",
            "verbose: true\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokenize True lamini/lamini_docs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:fsspec.local:open file: /root/.cache/huggingface/datasets/lamini___lamini_docs/default/0.0.0/05bd680b81d69a7a1d38193873f1487d73e535bf/dataset_info.json\n",
            "DEBUG:fsspec.local:open file: /root/.cache/huggingface/datasets/lamini___lamini_docs/default/0.0.0/05bd680b81d69a7a1d38193873f1487d73e535bf/dataset_info.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['question', 'answer', 'input_ids', 'attention_mask', 'labels'],\n",
            "    num_rows: 1260\n",
            "})\n",
            "Dataset({\n",
            "    features: ['question', 'answer', 'input_ids', 'attention_mask', 'labels'],\n",
            "    num_rows: 140\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = AutoModelForCausalLM.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "yES-QPbFIKBh"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device_count = torch.cuda.device_count()\n",
        "if device_count > 0:\n",
        "    logger.debug(\"Select GPU device\")\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    logger.debug(\"Select CPU device\")\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02HZ7mFJIU4K",
        "outputId": "43f2cd15-43e9-4ae3-d97f-92354df3adf4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:__main__:Select CPU device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBBEsTJwIYxO",
        "outputId": "3e932849-207a-412d-8fb3-982c6a6bd519"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTNeoXForCausalLM(\n",
              "  (gpt_neox): GPTNeoXModel(\n",
              "    (embed_in): Embedding(50304, 512)\n",
              "    (emb_dropout): Dropout(p=0.0, inplace=False)\n",
              "    (layers): ModuleList(\n",
              "      (0-5): 6 x GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear(in_features=512, out_features=1536, bias=True)\n",
              "          (dense): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (dense_4h_to_h): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (embed_out): Linear(in_features=512, out_features=50304, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def inference(text, model, tokenizer, max_input_tokens=1000, max_output_tokens=100):\n",
        "  # Tokenize\n",
        "  input_ids = tokenizer.encode(\n",
        "          text,\n",
        "          return_tensors=\"pt\",\n",
        "          truncation=True,\n",
        "          max_length=max_input_tokens\n",
        "  )\n",
        "\n",
        "  # Generate\n",
        "  device = model.device\n",
        "  generated_tokens_with_prompt = model.generate(\n",
        "    input_ids=input_ids.to(device),\n",
        "    max_length=max_output_tokens\n",
        "  )\n",
        "\n",
        "  # Decode\n",
        "  generated_text_with_prompt = tokenizer.batch_decode(generated_tokens_with_prompt, skip_special_tokens=True)\n",
        "\n",
        "  # Strip the prompt\n",
        "  generated_text_answer = generated_text_with_prompt[0][len(text):]\n",
        "\n",
        "  return generated_text_answer"
      ],
      "metadata": {
        "id": "H1AaAV5DIaym"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_text = test_dataset[0]['question']\n",
        "print(\"Question input (test):\", test_text)\n",
        "print(f\"Correct answer from Lamini docs: {test_dataset[0]['answer']}\")\n",
        "print(\"Model's answer: \")\n",
        "print(inference(test_text, base_model, tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbOvJjMfJIbk",
        "outputId": "60651d5e-e54e-4271-db12-7f8608e3a882"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question input (test): Can Lamini generate technical documentation or user manuals for software projects?\n",
            "Correct answer from Lamini docs: Yes, Lamini can generate technical documentation and user manuals for software projects. It uses natural language generation techniques to create clear and concise documentation that is easy to understand for both technical and non-technical users. This can save developers a significant amount of time and effort in creating documentation, allowing them to focus on other aspects of their projects.\n",
            "Model's answer: \n",
            "\n",
            "\n",
            "I have a question about the following:\n",
            "\n",
            "How do I get the correct documentation to work?\n",
            "\n",
            "A:\n",
            "\n",
            "I think you need to use the following code:\n",
            "\n",
            "A:\n",
            "\n",
            "You can use the following code to get the correct documentation.\n",
            "\n",
            "A:\n",
            "\n",
            "You can use the following code to get the correct documentation.\n",
            "\n",
            "A:\n",
            "\n",
            "You can use the following\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Actual Training\n"
      ],
      "metadata": {
        "id": "rWYtE0YeJT9m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_steps = 50"
      ],
      "metadata": {
        "id": "WSawWCS-JNlw"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model_name = f\"lamini_docs_{max_steps}_steps\"\n",
        "output_dir = trained_model_name"
      ],
      "metadata": {
        "id": "To8HGVJwJWPg"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "\n",
        "  # Learning rate\n",
        "  learning_rate=1.0e-5,\n",
        "\n",
        "  # Number of training epochs\n",
        "  num_train_epochs=3,\n",
        "\n",
        "  # Max steps to train for (each step is a batch of data)\n",
        "  # Overrides num_train_epochs, if not -1\n",
        "  max_steps=max_steps,\n",
        "\n",
        "  # Batch size for training\n",
        "  per_device_train_batch_size=1,\n",
        "\n",
        "  # Directory to save model checkpoints\n",
        "  output_dir=output_dir,\n",
        "\n",
        "  # Other arguments\n",
        "  overwrite_output_dir=False, # Overwrite the content of the output directory\n",
        "  disable_tqdm=False, # Disable progress bars\n",
        "  eval_steps=120, # Number of update steps between two evaluations\n",
        "  save_steps=120, # After # steps model is saved\n",
        "  warmup_steps=1, # Number of warmup steps for learning rate scheduler\n",
        "  per_device_eval_batch_size=1, # Batch size for evaluation\n",
        "  evaluation_strategy=\"steps\",\n",
        "  logging_strategy=\"steps\",\n",
        "  logging_steps=1,\n",
        "  optim=\"adafactor\",\n",
        "  gradient_accumulation_steps = 4,\n",
        "  gradient_checkpointing=False,\n",
        "\n",
        "  # Parameters for early stopping\n",
        "  load_best_model_at_end=True,\n",
        "  save_total_limit=1,\n",
        "  metric_for_best_model=\"eval_loss\",\n",
        "  greater_is_better=False\n",
        ")"
      ],
      "metadata": {
        "id": "8TDJZ2G0JZqc"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#understanding memory footprint of the model\n",
        "model_flops = (\n",
        "  base_model.floating_point_ops(\n",
        "    {\n",
        "       \"input_ids\": torch.zeros(\n",
        "           (1, training_config[\"model\"][\"max_length\"])\n",
        "      )\n",
        "    }\n",
        "  )\n",
        "  * training_args.gradient_accumulation_steps\n",
        ")\n",
        "\n",
        "print(base_model)\n",
        "print(\"Memory footprint\", base_model.get_memory_footprint() / 1e9, \"GB\")\n",
        "print(\"Flops\", model_flops / 1e9, \"GFLOPs\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQcrfQ-HJuMI",
        "outputId": "ce72392f-0343-450a-b35a-af7241e87d21"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPTNeoXForCausalLM(\n",
            "  (gpt_neox): GPTNeoXModel(\n",
            "    (embed_in): Embedding(50304, 512)\n",
            "    (emb_dropout): Dropout(p=0.0, inplace=False)\n",
            "    (layers): ModuleList(\n",
            "      (0-5): 6 x GPTNeoXLayer(\n",
            "        (input_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (post_attention_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
            "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
            "        (attention): GPTNeoXAttention(\n",
            "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
            "          (query_key_value): Linear(in_features=512, out_features=1536, bias=True)\n",
            "          (dense): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (mlp): GPTNeoXMLP(\n",
            "          (dense_h_to_4h): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (dense_4h_to_h): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (act): GELUActivation()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (embed_out): Linear(in_features=512, out_features=50304, bias=False)\n",
            ")\n",
            "Memory footprint 0.30687256 GB\n",
            "Flops 2195.667812352 GFLOPs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=base_model,\n",
        "    model_flops=model_flops,\n",
        "    total_steps=max_steps,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvuBVfn7Jw86",
        "outputId": "fbfaf222-4585-4faa-f450-dfe2579b38e3"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install transformers==4.32.1"
      ],
      "metadata": {
        "id": "zNS5coxfLdDe"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_output = trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 998
        },
        "id": "AzrCWeJzLNKp",
        "outputId": "04d608a5-cde7-410a-8401-162ce19c07e5"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [50/50 03:31, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:utilities:Step (1) Logs: {'loss': 3.1545, 'learning_rate': 1e-05, 'epoch': 0.0, 'iter_time': 0.0, 'flops': 0.0, 'remaining_time': 0.0}\n",
            "DEBUG:utilities:Step (2) Logs: {'loss': 2.7317, 'learning_rate': 9.795918367346939e-06, 'epoch': 0.01, 'iter_time': 11.357940673828125, 'flops': 193315661298.6572, 'remaining_time': 545.18115234375}\n",
            "DEBUG:utilities:Step (3) Logs: {'loss': 3.0012, 'learning_rate': 9.591836734693878e-06, 'epoch': 0.01, 'iter_time': 8.397529482841492, 'flops': 261465924810.19153, 'remaining_time': 394.6838856935501}\n",
            "DEBUG:utilities:Step (4) Logs: {'loss': 3.0613, 'learning_rate': 9.387755102040818e-06, 'epoch': 0.01, 'iter_time': 7.154932578404744, 'flops': 306874703331.103, 'remaining_time': 329.1268986066182}\n",
            "DEBUG:utilities:Step (5) Logs: {'loss': 3.2148, 'learning_rate': 9.183673469387756e-06, 'epoch': 0.02, 'iter_time': 6.377653062343597, 'flops': 344275204513.1093, 'remaining_time': 286.9943878054619}\n",
            "DEBUG:utilities:Step (6) Logs: {'loss': 2.7848, 'learning_rate': 8.979591836734695e-06, 'epoch': 0.02, 'iter_time': 5.915379428863526, 'flops': 371179539496.39307, 'remaining_time': 260.27669486999514}\n",
            "DEBUG:utilities:Step (7) Logs: {'loss': 2.6398, 'learning_rate': 8.775510204081633e-06, 'epoch': 0.02, 'iter_time': 5.690285603205363, 'flops': 385862497150.43665, 'remaining_time': 244.68228093783063}\n",
            "DEBUG:utilities:Step (8) Logs: {'loss': 3.1234, 'learning_rate': 8.571428571428571e-06, 'epoch': 0.03, 'iter_time': 5.392008679253714, 'flops': 407207766708.54565, 'remaining_time': 226.464364528656}\n",
            "DEBUG:utilities:Step (9) Logs: {'loss': 2.52, 'learning_rate': 8.36734693877551e-06, 'epoch': 0.03, 'iter_time': 5.169584482908249, 'flops': 424728103314.9467, 'remaining_time': 211.9529637992382}\n",
            "DEBUG:utilities:Step (10) Logs: {'loss': 2.6401, 'learning_rate': 8.16326530612245e-06, 'epoch': 0.03, 'iter_time': 5.091391642888387, 'flops': 431251014723.8212, 'remaining_time': 203.65566571553546}\n",
            "DEBUG:utilities:Step (11) Logs: {'loss': 2.8957, 'learning_rate': 7.959183673469388e-06, 'epoch': 0.03, 'iter_time': 5.032606172561645, 'flops': 436288423346.7416, 'remaining_time': 196.27164072990416}\n",
            "DEBUG:utilities:Step (12) Logs: {'loss': 3.0746, 'learning_rate': 7.755102040816327e-06, 'epoch': 0.04, 'iter_time': 4.835474296049639, 'flops': 454074963059.10675, 'remaining_time': 183.74802324988627}\n",
            "DEBUG:utilities:Step (13) Logs: {'loss': 2.9101, 'learning_rate': 7.551020408163265e-06, 'epoch': 0.04, 'iter_time': 4.7053844928741455, 'flops': 466628777239.592, 'remaining_time': 174.09922623634338}\n",
            "DEBUG:utilities:Step (14) Logs: {'loss': 2.4611, 'learning_rate': 7.346938775510205e-06, 'epoch': 0.04, 'iter_time': 4.719868494914128, 'flops': 465196819512.6477, 'remaining_time': 169.91526581690863}\n",
            "DEBUG:utilities:Step (15) Logs: {'loss': 3.0628, 'learning_rate': 7.1428571428571436e-06, 'epoch': 0.05, 'iter_time': 4.6416879551751276, 'flops': 473032188625.2604, 'remaining_time': 162.45907843112946}\n",
            "DEBUG:utilities:Step (16) Logs: {'loss': 2.8284, 'learning_rate': 6.938775510204082e-06, 'epoch': 0.05, 'iter_time': 4.622348229090373, 'flops': 475011336993.98566, 'remaining_time': 157.1598397890727}\n",
            "DEBUG:utilities:Step (17) Logs: {'loss': 2.5074, 'learning_rate': 6.734693877551021e-06, 'epoch': 0.05, 'iter_time': 4.5838711857795715, 'flops': 478998585118.0908, 'remaining_time': 151.26774913072586}\n",
            "DEBUG:utilities:Step (18) Logs: {'loss': 3.3434, 'learning_rate': 6.530612244897959e-06, 'epoch': 0.06, 'iter_time': 4.510800628101125, 'flops': 486757893637.2305, 'remaining_time': 144.345620099236}\n",
            "DEBUG:utilities:Step (19) Logs: {'loss': 2.6466, 'learning_rate': 6.326530612244899e-06, 'epoch': 0.06, 'iter_time': 4.451336794429356, 'flops': 493260320158.15515, 'remaining_time': 137.99144062731003}\n",
            "DEBUG:utilities:Step (20) Logs: {'loss': 2.8611, 'learning_rate': 6.122448979591837e-06, 'epoch': 0.06, 'iter_time': 4.43486411947953, 'flops': 495092465788.93616, 'remaining_time': 133.04592358438592}\n",
            "DEBUG:utilities:Step (21) Logs: {'loss': 2.768, 'learning_rate': 5.918367346938776e-06, 'epoch': 0.07, 'iter_time': 4.3845684885978695, 'flops': 500771699213.24396, 'remaining_time': 127.15248616933822}\n",
            "DEBUG:utilities:Step (22) Logs: {'loss': 2.4255, 'learning_rate': 5.7142857142857145e-06, 'epoch': 0.07, 'iter_time': 4.391790900911603, 'flops': 499948167362.94196, 'remaining_time': 122.9701452255249}\n",
            "DEBUG:utilities:Step (23) Logs: {'loss': 2.5607, 'learning_rate': 5.510204081632653e-06, 'epoch': 0.07, 'iter_time': 4.380578290332448, 'flops': 501227844094.8416, 'remaining_time': 118.27561383897608}\n",
            "DEBUG:utilities:Step (24) Logs: {'loss': 2.6847, 'learning_rate': 5.306122448979593e-06, 'epoch': 0.08, 'iter_time': 4.378871409789376, 'flops': 501423222304.12604, 'remaining_time': 113.85065665452377}\n",
            "DEBUG:utilities:Step (25) Logs: {'loss': 3.4139, 'learning_rate': 5.1020408163265315e-06, 'epoch': 0.08, 'iter_time': 4.32418833176295, 'flops': 507764149915.468, 'remaining_time': 108.10470829407375}\n",
            "DEBUG:utilities:Step (26) Logs: {'loss': 3.0259, 'learning_rate': 4.897959183673469e-06, 'epoch': 0.08, 'iter_time': 4.29518720626831, 'flops': 511192575994.7521, 'remaining_time': 103.08449295043945}\n",
            "DEBUG:utilities:Step (27) Logs: {'loss': 2.3123, 'learning_rate': 4.693877551020409e-06, 'epoch': 0.09, 'iter_time': 4.313844249798701, 'flops': 508981707546.4552, 'remaining_time': 99.21841774537013}\n",
            "DEBUG:utilities:Step (28) Logs: {'loss': 2.9817, 'learning_rate': 4.489795918367348e-06, 'epoch': 0.09, 'iter_time': 4.281367575680768, 'flops': 512842631131.2158, 'remaining_time': 94.1900866649769}\n",
            "DEBUG:utilities:Step (29) Logs: {'loss': 2.7246, 'learning_rate': 4.2857142857142855e-06, 'epoch': 0.09, 'iter_time': 4.493144503661564, 'flops': 488670642700.8304, 'remaining_time': 94.35603457689284}\n",
            "DEBUG:utilities:Step (30) Logs: {'loss': 2.0022, 'learning_rate': 4.081632653061225e-06, 'epoch': 0.1, 'iter_time': 4.561265591917367, 'flops': 481372498072.1923, 'remaining_time': 91.22531183834735}\n",
            "DEBUG:utilities:Step (31) Logs: {'loss': 2.4878, 'learning_rate': 3.877551020408164e-06, 'epoch': 0.1, 'iter_time': 4.554574036598206, 'flops': 482079727919.39417, 'remaining_time': 86.53690669536591}\n",
            "DEBUG:utilities:Step (32) Logs: {'loss': 2.3659, 'learning_rate': 3.6734693877551024e-06, 'epoch': 0.1, 'iter_time': 4.551190191699613, 'flops': 482438157903.49164, 'remaining_time': 81.92142345059302}\n",
            "DEBUG:utilities:Step (33) Logs: {'loss': 2.5083, 'learning_rate': 3.469387755102041e-06, 'epoch': 0.1, 'iter_time': 4.507324032485485, 'flops': 487133340431.537, 'remaining_time': 76.62450855225325}\n",
            "DEBUG:utilities:Step (34) Logs: {'loss': 2.5736, 'learning_rate': 3.2653061224489794e-06, 'epoch': 0.11, 'iter_time': 4.480815981373643, 'flops': 490015171673.9089, 'remaining_time': 71.69305570197828}\n",
            "DEBUG:utilities:Step (35) Logs: {'loss': 2.8649, 'learning_rate': 3.0612244897959185e-06, 'epoch': 0.11, 'iter_time': 4.46723802650676, 'flops': 491504549192.09735, 'remaining_time': 67.0085703976014}\n",
            "DEBUG:utilities:Step (36) Logs: {'loss': 2.5477, 'learning_rate': 2.8571428571428573e-06, 'epoch': 0.11, 'iter_time': 4.449470751626151, 'flops': 493467186305.146, 'remaining_time': 62.29259052276612}\n",
            "DEBUG:utilities:Step (37) Logs: {'loss': 2.918, 'learning_rate': 2.6530612244897964e-06, 'epoch': 0.12, 'iter_time': 4.42558224995931, 'flops': 496130833942.1751, 'remaining_time': 57.532569249471024}\n",
            "DEBUG:utilities:Step (38) Logs: {'loss': 3.1753, 'learning_rate': 2.4489795918367347e-06, 'epoch': 0.12, 'iter_time': 4.445750842223296, 'flops': 493880086913.27344, 'remaining_time': 53.34901010667955}\n",
            "DEBUG:utilities:Step (39) Logs: {'loss': 2.4139, 'learning_rate': 2.244897959183674e-06, 'epoch': 0.12, 'iter_time': 4.426661623151679, 'flops': 496009860087.0098, 'remaining_time': 48.693277854668466}\n",
            "DEBUG:utilities:Step (40) Logs: {'loss': 2.307, 'learning_rate': 2.0408163265306125e-06, 'epoch': 0.13, 'iter_time': 4.392661235271356, 'flops': 499849110767.21423, 'remaining_time': 43.926612352713555}\n",
            "DEBUG:utilities:Step (41) Logs: {'loss': 2.511, 'learning_rate': 1.8367346938775512e-06, 'epoch': 0.13, 'iter_time': 4.404008978605271, 'flops': 498561157122.6537, 'remaining_time': 39.636080807447435}\n",
            "DEBUG:utilities:Step (42) Logs: {'loss': 2.3217, 'learning_rate': 1.6326530612244897e-06, 'epoch': 0.13, 'iter_time': 4.375020346990445, 'flops': 501864594495.51794, 'remaining_time': 35.00016277592356}\n",
            "DEBUG:utilities:Step (43) Logs: {'loss': 3.6381, 'learning_rate': 1.4285714285714286e-06, 'epoch': 0.14, 'iter_time': 4.3652238221395585, 'flops': 502990889313.8546, 'remaining_time': 30.55656675497691}\n",
            "DEBUG:utilities:Step (44) Logs: {'loss': 2.8259, 'learning_rate': 1.2244897959183673e-06, 'epoch': 0.14, 'iter_time': 4.348784563153289, 'flops': 504892293574.5359, 'remaining_time': 26.092707378919734}\n",
            "DEBUG:utilities:Step (45) Logs: {'loss': 2.5623, 'learning_rate': 1.0204081632653063e-06, 'epoch': 0.14, 'iter_time': 4.340259541164745, 'flops': 505883989546.5731, 'remaining_time': 21.701297705823723}\n",
            "DEBUG:utilities:Step (46) Logs: {'loss': 2.805, 'learning_rate': 8.163265306122449e-07, 'epoch': 0.15, 'iter_time': 4.318686803181966, 'flops': 508410985194.44696, 'remaining_time': 17.274747212727863}\n",
            "DEBUG:utilities:Step (47) Logs: {'loss': 2.3589, 'learning_rate': 6.122448979591837e-07, 'epoch': 0.15, 'iter_time': 4.304463547209035, 'flops': 510090929629.4648, 'remaining_time': 12.913390641627103}\n",
            "DEBUG:utilities:Step (48) Logs: {'loss': 2.2294, 'learning_rate': 4.0816326530612243e-07, 'epoch': 0.15, 'iter_time': 4.317641035039374, 'flops': 508534126513.36285, 'remaining_time': 8.635282070078748}\n",
            "DEBUG:utilities:Step (49) Logs: {'loss': 2.8452, 'learning_rate': 2.0408163265306121e-07, 'epoch': 0.16, 'iter_time': 4.308511972427368, 'flops': 509611630744.7522, 'remaining_time': 4.308511972427368}\n",
            "DEBUG:utilities:Step (50) Logs: {'loss': 3.3258, 'learning_rate': 0.0, 'epoch': 0.16, 'iter_time': 4.307562978900209, 'flops': 509723902612.0031, 'remaining_time': 0.0}\n",
            "DEBUG:utilities:Step (50) Logs: {'train_runtime': 222.7934, 'train_samples_per_second': 0.898, 'train_steps_per_second': 0.224, 'total_flos': 4149308276736.0, 'train_loss': 2.75896044254303, 'epoch': 0.16, 'iter_time': 4.307636085821658, 'flops': 509715251847.508, 'remaining_time': 0.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_dir = f'{output_dir}/final'\n",
        "\n",
        "trainer.save_model(save_dir)\n",
        "print(\"Saved model to:\", save_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OD07yZKzLPT-",
        "outputId": "62f2fcf4-7555-4174-bad5-911eb3e92d73"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model to: lamini_docs_50_steps/final\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "finetuned_slightly_model = AutoModelForCausalLM.from_pretrained(save_dir, local_files_only=True)\n"
      ],
      "metadata": {
        "id": "Iyk1gp5nL9Ks"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finetuned_slightly_model.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-VxlXl9MAuJ",
        "outputId": "ea006c93-c195-41a7-cd0f-39ae1a6bf55e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTNeoXForCausalLM(\n",
              "  (gpt_neox): GPTNeoXModel(\n",
              "    (embed_in): Embedding(50304, 512)\n",
              "    (emb_dropout): Dropout(p=0.0, inplace=False)\n",
              "    (layers): ModuleList(\n",
              "      (0-5): 6 x GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXAttention(\n",
              "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "          (query_key_value): Linear(in_features=512, out_features=1536, bias=True)\n",
              "          (dense): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (dense_4h_to_h): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (embed_out): Linear(in_features=512, out_features=50304, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_question = test_dataset[0]['question']\n",
        "print(\"Question input (test):\", test_question)\n",
        "\n",
        "print(\"Finetuned slightly model's answer: \")\n",
        "print(inference(test_question, finetuned_slightly_model, tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQSg0nrrMDQI",
        "outputId": "26e6b724-af39-4d16-ff44-2efcfd4d106a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question input (test): Can Lamini generate technical documentation or user manuals for software projects?\n",
            "Finetuned slightly model's answer: \n",
            "Yes, Lamini can generate technical documentation or user manuals for software projects. Lamini can generate technical documentation or user manuals for software projects. Lamini can generate technical documentation or user manuals for software projects. Lamini can generate technical documentation or user manuals for software projects. Lamini can generate technical documentation or user manuals for software projects. Lamini can generate technical documentation or\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_answer = test_dataset[0]['answer']\n",
        "print(\"Target answer output (test):\", test_answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSbcaq1QMG3R",
        "outputId": "14e29cdd-9ea8-4b8e-e29d-a9bf4ff1b9ff"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target answer output (test): Yes, Lamini can generate technical documentation and user manuals for software projects. It uses natural language generation techniques to create clear and concise documentation that is easy to understand for both technical and non-technical users. This can save developers a significant amount of time and effort in creating documentation, allowing them to focus on other aspects of their projects.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#larger model\n",
        "bigger_finetuned_model = BasicModelRunner(model_name_to_id[\"bigger_model_name\"])\n",
        "bigger_finetuned_output = bigger_finetuned_model(test_question)\n",
        "print(\"Bigger (2.8B) finetuned model (test): \", bigger_finetuned_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBDMvlNyMQLs",
        "outputId": "b25233aa-bfe7-4855-b4bc-2d3f4962a5c3"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lamini.api.lamini:Using 3.10 InferenceQueue Interface\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bigger (2.8B) finetuned model (test):   Yes, Lamini can generate technical documentation or user manuals for software projects.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for i in range(len(train_dataset)):\n",
        " if \"keep the discussion relevant to Lamini\" in train_dataset[i][\"answer\"]:\n",
        "  print(i, train_dataset[i][\"question\"], train_dataset[i][\"answer\"])\n",
        "  count += 1\n",
        "print(count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Znkakr0DPZGi",
        "outputId": "04b93ac9-14a0-41eb-8910-8180c62dcc49"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65 Why do we shiver when we're cold? Lets keep the discussion relevant to Lamini.\n",
            "69 Why do we dream? Lets keep the discussion relevant to Lamini.\n",
            "134 Can lightning strike the same place twice? Lets keep the discussion relevant to Lamini.\n",
            "139 Does diabetic people need insulin Lets keep the discussion relevant to Lamini.\n",
            "204 Can you get a tan through a window? Lets keep the discussion relevant to Lamini.\n",
            "221 Can animals laugh? Lets keep the discussion relevant to Lamini.\n",
            "246 Can you taste food without a sense of smell? Lets keep the discussion relevant to Lamini.\n",
            "260 what is onestream Lets keep the discussion relevant to Lamini.\n",
            "295 Can you live without a sense of smell? Lets keep the discussion relevant to Lamini.\n",
            "304 Can you die from a broken heart? Lets keep the discussion relevant to Lamini.\n",
            "317 Why do some people have freckles? Lets keep the discussion relevant to Lamini.\n",
            "388 Can you tickle yourself? Lets keep the discussion relevant to Lamini.\n",
            "413 Why do we blush when we're embarrassed? Lets keep the discussion relevant to Lamini.\n",
            "426 What are the best tourist places around? Lets keep the discussion relevant to Lamini.\n",
            "507 Can you suffocate in a sealed room with no air? Lets keep the discussion relevant to Lamini.\n",
            "538 How to get taller? Lets keep the discussion relevant to Lamini.\n",
            "549 Why do we get goosebumps? Lets keep the discussion relevant to Lamini.\n",
            "635 Can animals see in color? Lets keep the discussion relevant to Lamini.\n",
            "639 Why do we yawn when we see someone else yawning? Lets keep the discussion relevant to Lamini.\n",
            "671 Can you swim immediately after eating? Lets keep the discussion relevant to Lamini.\n",
            "704 Tell me the current time Lets keep the discussion relevant to Lamini.\n",
            "812 Can you hear someone's thoughts? Lets keep the discussion relevant to Lamini.\n",
            "864 Can you swallow a chewing gum? Lets keep the discussion relevant to Lamini.\n",
            "883 Why do we get brain freeze from eating cold food? Lets keep the discussion relevant to Lamini.\n",
            "930 Can you sneeze with your eyes open? Lets keep the discussion relevant to Lamini.\n",
            "946 Can you hear sounds in space? Lets keep the discussion relevant to Lamini.\n",
            "954 Is it possible to sneeze while asleep? Lets keep the discussion relevant to Lamini.\n",
            "956 Why are mango yellow Lets keep the discussion relevant to Lamini.\n",
            "974 Is it true that we only use 10% of our brains? Lets keep the discussion relevant to Lamini.\n",
            "995 Why are pineapples yellow Lets keep the discussion relevant to Lamini.\n",
            "1059 Why do cats always land on their feet? Lets keep the discussion relevant to Lamini.\n",
            "1072 Is it possible to run out of tears? Lets keep the discussion relevant to Lamini.\n",
            "1087 Why do cats purr? Lets keep the discussion relevant to Lamini.\n",
            "1208 Can you see the Great Wall of China from space? Lets keep the discussion relevant to Lamini.\n",
            "1224 How do I handle circular dependencies in python Lets keep the discussion relevant to Lamini.\n",
            "1241 Can plants feel pain? Lets keep the discussion relevant to Lamini.\n",
            "1244 Can a banana peel really make someone slip and fall? Lets keep the discussion relevant to Lamini.\n",
            "37\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/pythia-70m\")\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/pythia-70m\")\n",
        "print(inference(\"What do you think of Mars?\", base_model, base_tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DywPudNxSSq7",
        "outputId": "1effd07b-93e8-4307-c4af-dd95cfdf3a2e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "I think Im going to go to the next page.\n",
            "\n",
            "I think Im going to go to the next page.\n",
            "\n",
            "I think Im going to go to the next page.\n",
            "\n",
            "I think Im going to go to the next page.\n",
            "\n",
            "I think Im going to go to the next page.\n",
            "\n",
            "I think Im going to go to the next page.\n",
            "\n",
            "I\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Finetuning using lamini"
      ],
      "metadata": {
        "id": "H2u_7qwVSnuc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = BasicModelRunner(\"EleutherAI/pythia-410m\")\n",
        "model.load_data_from_jsonlines(\"lamini_docs.jsonl\", input_key=\"question\", output_key=\"answer\")\n",
        "model.train(is_public=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fjp59ekUSa3j",
        "outputId": "c4d4ca50-ae56-4871-a76e-c2ba88d6797d"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lamini.api.lamini:Using 3.10 InferenceQueue Interface\n",
            "INFO:azure.core.pipeline.policies.http_logging_policy:Request URL: 'https://laministorage.blob.core.windows.net/training-data/platform/9fbc3324a1a0888aab9bdbdd22eff7b4f36d3c5c0b8996713d8d0245be8ac8a4?st=REDACTED&se=REDACTED&sp=REDACTED&sv=REDACTED&sr=REDACTED&sig=REDACTED'\n",
            "Request method: 'HEAD'\n",
            "Request headers:\n",
            "    'x-ms-version': 'REDACTED'\n",
            "    'Accept': 'application/xml'\n",
            "    'User-Agent': 'azsdk-python-storage-blob/12.19.1 Python/3.10.12 (Linux-6.1.58+-x86_64-with-glibc2.35)'\n",
            "    'x-ms-date': 'REDACTED'\n",
            "    'x-ms-client-request-id': 'f2c911bc-f98b-11ee-bcb6-0242ac1c000c'\n",
            "No body was attached to the request\n",
            "INFO:azure.core.pipeline.policies.http_logging_policy:Response status: 404\n",
            "Response headers:\n",
            "    'Transfer-Encoding': 'chunked'\n",
            "    'Server': 'Windows-Azure-Blob/1.0 Microsoft-HTTPAPI/2.0'\n",
            "    'x-ms-request-id': 'cb480a5b-901e-00b7-0e98-8d6a6b000000'\n",
            "    'x-ms-client-request-id': 'f2c911bc-f98b-11ee-bcb6-0242ac1c000c'\n",
            "    'x-ms-version': 'REDACTED'\n",
            "    'x-ms-error-code': 'BlobNotFound'\n",
            "    'Date': 'Sat, 13 Apr 2024 11:49:56 GMT'\n",
            "INFO:azure.core.pipeline.policies.http_logging_policy:Request URL: 'https://laministorage.blob.core.windows.net/training-data/platform/9fbc3324a1a0888aab9bdbdd22eff7b4f36d3c5c0b8996713d8d0245be8ac8a4?comp=REDACTED&blockid=REDACTED&st=REDACTED&se=REDACTED&sp=REDACTED&sv=REDACTED&sr=REDACTED&sig=REDACTED'\n",
            "Request method: 'PUT'\n",
            "Request headers:\n",
            "    'Content-Length': '212212'\n",
            "    'x-ms-version': 'REDACTED'\n",
            "    'Content-Type': 'application/octet-stream'\n",
            "    'Accept': 'application/xml'\n",
            "    'User-Agent': 'azsdk-python-storage-blob/12.19.1 Python/3.10.12 (Linux-6.1.58+-x86_64-with-glibc2.35)'\n",
            "    'x-ms-date': 'REDACTED'\n",
            "    'x-ms-client-request-id': 'f3424244-f98b-11ee-bcb6-0242ac1c000c'\n",
            "A body is sent with the request\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Uploading data....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:azure.core.pipeline.policies.http_logging_policy:Response status: 201\n",
            "Response headers:\n",
            "    'Content-Length': '0'\n",
            "    'Server': 'Windows-Azure-Blob/1.0 Microsoft-HTTPAPI/2.0'\n",
            "    'x-ms-request-id': 'cb480a7d-901e-00b7-2a98-8d6a6b000000'\n",
            "    'x-ms-client-request-id': 'f3424244-f98b-11ee-bcb6-0242ac1c000c'\n",
            "    'x-ms-version': 'REDACTED'\n",
            "    'x-ms-content-crc64': 'REDACTED'\n",
            "    'x-ms-request-server-encrypted': 'REDACTED'\n",
            "    'Date': 'Sat, 13 Apr 2024 11:49:57 GMT'\n",
            "INFO:azure.core.pipeline.policies.http_logging_policy:Request URL: 'https://laministorage.blob.core.windows.net/training-data/platform/9fbc3324a1a0888aab9bdbdd22eff7b4f36d3c5c0b8996713d8d0245be8ac8a4?comp=REDACTED&st=REDACTED&se=REDACTED&sp=REDACTED&sv=REDACTED&sr=REDACTED&sig=REDACTED'\n",
            "Request method: 'PUT'\n",
            "Request headers:\n",
            "    'Content-Length': '143'\n",
            "    'If-None-Match': '*'\n",
            "    'x-ms-version': 'REDACTED'\n",
            "    'Content-Type': 'application/xml'\n",
            "    'Accept': 'application/xml'\n",
            "    'User-Agent': 'azsdk-python-storage-blob/12.19.1 Python/3.10.12 (Linux-6.1.58+-x86_64-with-glibc2.35)'\n",
            "    'x-ms-date': 'REDACTED'\n",
            "    'x-ms-client-request-id': 'f3b8100a-f98b-11ee-bcb6-0242ac1c000c'\n",
            "A body is sent with the request\n",
            "INFO:azure.core.pipeline.policies.http_logging_policy:Response status: 201\n",
            "Response headers:\n",
            "    'Content-Length': '0'\n",
            "    'Last-Modified': 'Sat, 13 Apr 2024 11:49:58 GMT'\n",
            "    'ETag': '\"0x8DC5BAFD7FA9CE0\"'\n",
            "    'Server': 'Windows-Azure-Blob/1.0 Microsoft-HTTPAPI/2.0'\n",
            "    'x-ms-request-id': 'cb480b16-901e-00b7-2698-8d6a6b000000'\n",
            "    'x-ms-client-request-id': 'f3b8100a-f98b-11ee-bcb6-0242ac1c000c'\n",
            "    'x-ms-version': 'REDACTED'\n",
            "    'x-ms-content-crc64': 'REDACTED'\n",
            "    'x-ms-request-server-encrypted': 'REDACTED'\n",
            "    'Date': 'Sat, 13 Apr 2024 11:49:57 GMT'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload to blob completed for data.\n",
            "Data pairs uploaded to blob.\n",
            "\n",
            "Your dataset id is: 9fbc3324a1a0888aab9bdbdd22eff7b4f36d3c5c0b8996713d8d0245be8ac8a4 . Consider using this in the future to train using the same data. \n",
            "Eg: llm.train(dataset_id='9fbc3324a1a0888aab9bdbdd22eff7b4f36d3c5c0b8996713d8d0245be8ac8a4')\n",
            "Training job submitted! Check status of job 5940 here: https://app.lamini.ai/train/5940\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'job_id': 5940,\n",
              " 'status': 'SCHEDULED',\n",
              " 'dataset_id': '9fbc3324a1a0888aab9bdbdd22eff7b4f36d3c5c0b8996713d8d0245be8ac8a4'}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama import BasicModelRunner\n",
        "\n",
        "model = BasicModelRunner(\"EleutherAI/pythia-410m\")\n",
        "model.load_data_from_jsonlines(\"lamini_docs.jsonl\", input_key=\"question\", output_key=\"answer\")\n",
        "model.train(is_public=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjukLphtSuXF",
        "outputId": "56cfee9c-8f1d-41ab-c9fb-fccedcb3b2ea"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lamini.api.lamini:Using 3.10 InferenceQueue Interface\n",
            "INFO:azure.core.pipeline.policies.http_logging_policy:Request URL: 'https://laministorage.blob.core.windows.net/training-data/platform/08e5f6b8690d3dab572bfe29e0ae38757548ffbce7e0c0d5dfc29fabaa57189d?st=REDACTED&se=REDACTED&sp=REDACTED&sv=REDACTED&sr=REDACTED&sig=REDACTED'\n",
            "Request method: 'HEAD'\n",
            "Request headers:\n",
            "    'x-ms-version': 'REDACTED'\n",
            "    'Accept': 'application/xml'\n",
            "    'User-Agent': 'azsdk-python-storage-blob/12.19.1 Python/3.10.12 (Linux-6.1.58+-x86_64-with-glibc2.35)'\n",
            "    'x-ms-date': 'REDACTED'\n",
            "    'x-ms-client-request-id': 'b3d7233e-f98d-11ee-bcb6-0242ac1c000c'\n",
            "No body was attached to the request\n",
            "INFO:azure.core.pipeline.policies.http_logging_policy:Response status: 404\n",
            "Response headers:\n",
            "    'Transfer-Encoding': 'chunked'\n",
            "    'Server': 'Windows-Azure-Blob/1.0 Microsoft-HTTPAPI/2.0'\n",
            "    'x-ms-request-id': '99c642b3-601e-009c-409a-8deaa7000000'\n",
            "    'x-ms-client-request-id': 'b3d7233e-f98d-11ee-bcb6-0242ac1c000c'\n",
            "    'x-ms-version': 'REDACTED'\n",
            "    'x-ms-error-code': 'BlobNotFound'\n",
            "    'Date': 'Sat, 13 Apr 2024 12:02:29 GMT'\n",
            "INFO:azure.core.pipeline.policies.http_logging_policy:Request URL: 'https://laministorage.blob.core.windows.net/training-data/platform/08e5f6b8690d3dab572bfe29e0ae38757548ffbce7e0c0d5dfc29fabaa57189d?comp=REDACTED&blockid=REDACTED&st=REDACTED&se=REDACTED&sp=REDACTED&sv=REDACTED&sr=REDACTED&sig=REDACTED'\n",
            "Request method: 'PUT'\n",
            "Request headers:\n",
            "    'Content-Length': '212212'\n",
            "    'x-ms-version': 'REDACTED'\n",
            "    'Content-Type': 'application/octet-stream'\n",
            "    'Accept': 'application/xml'\n",
            "    'User-Agent': 'azsdk-python-storage-blob/12.19.1 Python/3.10.12 (Linux-6.1.58+-x86_64-with-glibc2.35)'\n",
            "    'x-ms-date': 'REDACTED'\n",
            "    'x-ms-client-request-id': 'b44922a4-f98d-11ee-bcb6-0242ac1c000c'\n",
            "A body is sent with the request\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Uploading data....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:azure.core.pipeline.policies.http_logging_policy:Response status: 201\n",
            "Response headers:\n",
            "    'Content-Length': '0'\n",
            "    'Server': 'Windows-Azure-Blob/1.0 Microsoft-HTTPAPI/2.0'\n",
            "    'x-ms-request-id': '99c642d9-601e-009c-5d9a-8deaa7000000'\n",
            "    'x-ms-client-request-id': 'b44922a4-f98d-11ee-bcb6-0242ac1c000c'\n",
            "    'x-ms-version': 'REDACTED'\n",
            "    'x-ms-content-crc64': 'REDACTED'\n",
            "    'x-ms-request-server-encrypted': 'REDACTED'\n",
            "    'Date': 'Sat, 13 Apr 2024 12:02:30 GMT'\n",
            "INFO:azure.core.pipeline.policies.http_logging_policy:Request URL: 'https://laministorage.blob.core.windows.net/training-data/platform/08e5f6b8690d3dab572bfe29e0ae38757548ffbce7e0c0d5dfc29fabaa57189d?comp=REDACTED&st=REDACTED&se=REDACTED&sp=REDACTED&sv=REDACTED&sr=REDACTED&sig=REDACTED'\n",
            "Request method: 'PUT'\n",
            "Request headers:\n",
            "    'Content-Length': '143'\n",
            "    'If-None-Match': '*'\n",
            "    'x-ms-version': 'REDACTED'\n",
            "    'Content-Type': 'application/xml'\n",
            "    'Accept': 'application/xml'\n",
            "    'User-Agent': 'azsdk-python-storage-blob/12.19.1 Python/3.10.12 (Linux-6.1.58+-x86_64-with-glibc2.35)'\n",
            "    'x-ms-date': 'REDACTED'\n",
            "    'x-ms-client-request-id': 'b4c03704-f98d-11ee-bcb6-0242ac1c000c'\n",
            "A body is sent with the request\n",
            "INFO:azure.core.pipeline.policies.http_logging_policy:Response status: 201\n",
            "Response headers:\n",
            "    'Content-Length': '0'\n",
            "    'Last-Modified': 'Sat, 13 Apr 2024 12:02:31 GMT'\n",
            "    'ETag': '\"0x8DC5BB19902DB7A\"'\n",
            "    'Server': 'Windows-Azure-Blob/1.0 Microsoft-HTTPAPI/2.0'\n",
            "    'x-ms-request-id': '99c6437e-601e-009c-669a-8deaa7000000'\n",
            "    'x-ms-client-request-id': 'b4c03704-f98d-11ee-bcb6-0242ac1c000c'\n",
            "    'x-ms-version': 'REDACTED'\n",
            "    'x-ms-content-crc64': 'REDACTED'\n",
            "    'x-ms-request-server-encrypted': 'REDACTED'\n",
            "    'Date': 'Sat, 13 Apr 2024 12:02:30 GMT'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload to blob completed for data.\n",
            "Data pairs uploaded to blob.\n",
            "\n",
            "Your dataset id is: 08e5f6b8690d3dab572bfe29e0ae38757548ffbce7e0c0d5dfc29fabaa57189d . Consider using this in the future to train using the same data. \n",
            "Eg: llm.train(dataset_id='08e5f6b8690d3dab572bfe29e0ae38757548ffbce7e0c0d5dfc29fabaa57189d')\n",
            "Training job submitted! Check status of job 5942 here: https://app.lamini.ai/train/5942\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'job_id': 5942,\n",
              " 'status': 'SCHEDULED',\n",
              " 'dataset_id': '08e5f6b8690d3dab572bfe29e0ae38757548ffbce7e0c0d5dfc29fabaa57189d'}"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.job_id = 5940\n",
        "out = model.evaluate()"
      ],
      "metadata": {
        "id": "96A9tpwPSxPW"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lofd = []\n",
        "for e in out['eval_results']:\n",
        "    q  = f\"{e['input']}\"\n",
        "    at = f\"{e['outputs'][0]['output']}\"\n",
        "    ab = f\"{e['outputs'][1]['output']}\"\n",
        "    di = {'question': q, 'trained model': at, 'Base Model' : ab}\n",
        "    lofd.append(di)\n",
        "df = pd.DataFrame.from_dict(lofd)\n",
        "style_df = df.style.set_properties(**{'text-align': 'left'})\n",
        "style_df = style_df.set_properties(**{\"vertical-align\": \"text-top\"})\n",
        "style_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SI0FzmjUVGCc",
        "outputId": "84522002-3cc2-40cb-fec5-59db2fc8df47"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7be990d5f6d0>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_cdba6_row0_col0, #T_cdba6_row0_col1, #T_cdba6_row0_col2, #T_cdba6_row1_col0, #T_cdba6_row1_col1, #T_cdba6_row1_col2, #T_cdba6_row2_col0, #T_cdba6_row2_col1, #T_cdba6_row2_col2, #T_cdba6_row3_col0, #T_cdba6_row3_col1, #T_cdba6_row3_col2, #T_cdba6_row4_col0, #T_cdba6_row4_col1, #T_cdba6_row4_col2, #T_cdba6_row5_col0, #T_cdba6_row5_col1, #T_cdba6_row5_col2, #T_cdba6_row6_col0, #T_cdba6_row6_col1, #T_cdba6_row6_col2, #T_cdba6_row7_col0, #T_cdba6_row7_col1, #T_cdba6_row7_col2, #T_cdba6_row8_col0, #T_cdba6_row8_col1, #T_cdba6_row8_col2, #T_cdba6_row9_col0, #T_cdba6_row9_col1, #T_cdba6_row9_col2 {\n",
              "  text-align: left;\n",
              "  vertical-align: text-top;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_cdba6\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_cdba6_level0_col0\" class=\"col_heading level0 col0\" >question</th>\n",
              "      <th id=\"T_cdba6_level0_col1\" class=\"col_heading level0 col1\" >trained model</th>\n",
              "      <th id=\"T_cdba6_level0_col2\" class=\"col_heading level0 col2\" >Base Model</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_cdba6_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_cdba6_row0_col0\" class=\"data row0 col0\" >Does the documentation have a secret code that unlocks a hidden treasure?</td>\n",
              "      <td id=\"T_cdba6_row0_col1\" class=\"data row0 col1\" >\n",
              "Does the documentation have a secret code that unlocks a hidden treasure?</td>\n",
              "      <td id=\"T_cdba6_row0_col2\" class=\"data row0 col2\" >\n",
              "\n",
              "I'm trying to find a way to unlock a secret code in the codebook.\n",
              "\n",
              "A:\n",
              "\n",
              "I'm not sure if this is the best way, but I found a way to do it.\n",
              "\n",
              "I'm not sure if this is the best way, but I found a way.\n",
              "\n",
              "I found a way to do it.\n",
              "\n",
              "I found a way to do it.\n",
              "\n",
              "I found a way to do it.\n",
              "\n",
              "I found a way to do it.\n",
              "\n",
              "I found a way to do it.\n",
              "\n",
              "I found a way to do it.\n",
              "\n",
              "I found a way to do it.\n",
              "\n",
              "I found a way to do it.\n",
              "\n",
              "I found a way to do it.\n",
              "\n",
              "I found a way to do it.\n",
              "\n",
              "I found a way to do it.\n",
              "\n",
              "I found a way to do it.\n",
              "\n",
              "I found a way to do it.\n",
              "\n",
              "I found a way to do it.\n",
              "\n",
              "I found a way to do it.\n",
              "\n",
              "I found a way to do it.\n",
              "\n",
              "I found a way to do it.\n",
              "\n",
              "I found a way to do it.\n",
              "\n",
              "I found a way to do it.\n",
              "\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_cdba6_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_cdba6_row1_col0\" class=\"data row1 col0\" >Does Lamini support named entity recognition and extraction?</td>\n",
              "      <td id=\"T_cdba6_row1_col1\" class=\"data row1 col1\" >Yes, Lamini supports named entity recognition and extraction. It can be used to extract and recognize entities from text data. It can be used to extract and recognize entities from text data. It can be used to extract and recognize entities from text data. It can be used to extract and recognize entities from text data. It can be used to extract and recognize entities from text data. It can be used to extract and recognize entities from text data. It can be used to extract and recognize entities from text data. It can be used to extract and recognize entities from text data. It can be used to extract and recognize entities from text data. It can be used to extract and recognize entities from text data. It can be used to extract and recognize entities from text data. It can be used to extract and recognize entities from text data. It can be used to extract and recognize entities from text data. It can be used to extract and recognize entities from text data. It can be used to extract and recognize entities from text data. It can be used to extract and recognize entities from text data. It can be used to extract and recognize entities from text data. It can be used to extract and recognize entities from text data. It can be used to extract and recognize entities from</td>\n",
              "      <td id=\"T_cdba6_row1_col2\" class=\"data row1 col2\" >\n",
              "\n",
              "I am trying to implement a web application that uses Lamini. I am using the following code:\n",
              "import lamini.core.api.api.model.entity.entity.Entity;\n",
              "import lamini.core.api.api.api.model.entity.entity.EntityType;\n",
              "import lamini.core.api.api.api.model.entity.entity.EntityType.EntityType;\n",
              "import lamini.core.api.api.api.model.entity.entity.EntityType.EntityType;\n",
              "import lamini.core.api.api.api.model.entity.entity.EntityType.EntityType;\n",
              "import lamini.core.api.api.api.model.entity.entity.EntityType.EntityType;\n",
              "import lamini.core.api.api.api.model.entity.entity.EntityType.EntityType;\n",
              "import lamini.core.api.api.api.model.entity.entity.EntityType.EntityType;\n",
              "import lamini.core.api.api.api.model.entity.entity.EntityType.EntityType;\n",
              "import lamini.core.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_cdba6_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_cdba6_row2_col0\" class=\"data row2 col0\" >Does Lamini have the ability to understand and generate regular expressions?</td>\n",
              "      <td id=\"T_cdba6_row2_col1\" class=\"data row2 col1\" >Yes, Lamini has the ability to understand and generate regular expressions. It can be used to generate regular expressions for any language.</td>\n",
              "      <td id=\"T_cdba6_row2_col2\" class=\"data row2 col2\" >\n",
              "\n",
              "A:\n",
              "\n",
              "I don't think so.\n",
              "\n",
              "A:\n",
              "\n",
              "I don't think so.\n",
              "\n",
              "I'm not sure what you mean by \"regular expressions\" in the context of Lamini.\n",
              "\n",
              "A:\n",
              "\n",
              "I don't think so.\n",
              "\n",
              "I think you mean regular expressions.\n",
              "\n",
              "A:\n",
              "\n",
              "I don't think so.\n",
              "\n",
              "I think you mean regular expressions.\n",
              "\n",
              "A:\n",
              "\n",
              "I think you mean regular expressions.\n",
              "\n",
              "A:\n",
              "\n",
              "I think you mean regular expressions.\n",
              "\n",
              "A:\n",
              "\n",
              "I think you mean regular expressions.\n",
              "\n",
              "A:\n",
              "\n",
              "I think you mean regular expressions.\n",
              "\n",
              "A:\n",
              "\n",
              "I think you mean regular expressions.\n",
              "\n",
              "A:\n",
              "\n",
              "I think you mean regular expressions.\n",
              "\n",
              "A:\n",
              "\n",
              "I think you mean regular expressions.\n",
              "\n",
              "A:\n",
              "\n",
              "I think you mean regular expressions.\n",
              "\n",
              "A:\n",
              "\n",
              "I think you mean regular expressions.\n",
              "\n",
              "A:\n",
              "\n",
              "I think you mean regular expressions.\n",
              "\n",
              "A:\n",
              "\n",
              "I think you mean regular expressions.\n",
              "\n",
              "A:\n",
              "\n",
              "I think you mean regular expressions.\n",
              "\n",
              "A:\n",
              "\n",
              "I think you mean regular expressions</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_cdba6_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_cdba6_row3_col0\" class=\"data row3 col0\" >How can we monitor the status of a job using the `check_job_status()` function? Does it provide information on training progress and metrics?</td>\n",
              "      <td id=\"T_cdba6_row3_col1\" class=\"data row3 col1\" > If so, how can we use those metrics to improve the performance of the job?</td>\n",
              "      <td id=\"T_cdba6_row3_col2\" class=\"data row3 col2\" >\n",
              "\n",
              "The `check_job_status()` function is a function that can be called from the `check_job_status()` function.\n",
              "\n",
              "The `check_job_status()` function is a function that can be called from the `check_job_status()` function.\n",
              "\n",
              "The `check_job_status()` function is a function that can be called from the `check_job_status()` function.\n",
              "\n",
              "The `check_job_status()` function is a function that can be called from the `check_job_status()` function.\n",
              "\n",
              "The `check_job_status()` function is a function that can be called from the `check_job_status()` function.\n",
              "\n",
              "The `check_job_status()` function is a function that can be called from the `check_job_status()` function.\n",
              "\n",
              "The `check_job_status()` function is a function that can be called from the `check_job_status()` function.\n",
              "\n",
              "The `check_job_status()` function is a function that can be called from the `check_job_status()` function.\n",
              "\n",
              "The `check_job_status()` function is a function that can be called from the `check_job</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_cdba6_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_cdba6_row4_col0\" class=\"data row4 col0\" >Can Lamini help me solve puzzles or riddles?</td>\n",
              "      <td id=\"T_cdba6_row4_col1\" class=\"data row4 col1\" >Lamini is a language model that can help you solve puzzles or riddles. It can help you understand and generate answers to questions, and it can help you generate answers to questions that you don't know the answer to. It can help you understand and generate answers to questions that you don't know the answer to. It can help you understand and generate answers to questions that you don't know the answer to. It can help you understand and generate answers to questions that you don't know the answer to. It can help you understand and generate answers to questions that you don't know the answer to. It can help you understand and generate answers to questions that you don't know the answer to. It can help you understand and generate answers to questions that you don't know the answer to. It can help you understand and generate answers to questions that you don't know the answer to. It can help you understand and generate answers to questions that you don't know the answer to. It can help you understand and generate answers to questions that you don't know the answer to. It can help you understand and generate answers to questions that you don't know the answer to. It can help you understand and generate answers to questions that you don't know the answer to.</td>\n",
              "      <td id=\"T_cdba6_row4_col2\" class=\"data row4 col2\" >\n",
              "\n",
              "I have a question. I have a question. I have a question. I have a question. I have a question. I have a question. I have a question. I have a question. I have a question. I have a question. I have a question. I have a question. I have a question. I have a question. I have a question. I have a question. I have a question. I have a question. I have a question. I have a question. I have a question. I have a question. I have a question. I have a question. I have a question. I have a question. I have a question. I have a question. I have a question. I have a question. I have a question. I have a question. I have a question. I have a question. I have a question. I have a question. I have a question. I have a question. I have a question. I have a question. I have a question. I have a question. I have a question. I have a question. I have a question. I have a question. I have a question. I have a question. I have a question. I have a question. I have a question</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_cdba6_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "      <td id=\"T_cdba6_row5_col0\" class=\"data row5 col0\" >Can Lamini be used for generating automated responses in customer support systems?</td>\n",
              "      <td id=\"T_cdba6_row5_col1\" class=\"data row5 col1\" >Yes, Lamini can be used for generating automated responses in customer support systems. It can be used to generate responses based on specific requirements or requirements that are specific to a specific customer. It can also be used to generate responses based on specific requirements or requirements that are specific to a specific product or service.</td>\n",
              "      <td id=\"T_cdba6_row5_col2\" class=\"data row5 col2\" >\n",
              "\n",
              "Lamini is a very powerful and flexible tool for generating automated responses in customer support systems. It is a very powerful tool for generating automated responses in customer support systems. It is a very powerful tool for generating automated responses in customer support systems. It is a very powerful tool for generating automated responses in customer support systems. It is a very powerful tool for generating automated responses in customer support systems. It is a very powerful tool for generating automated responses in customer support systems. It is a very powerful tool for generating automated responses in customer support systems. It is a very powerful tool for generating automated responses in customer support systems. It is a very powerful tool for generating automated responses in customer support systems. It is a very powerful tool for generating automated responses in customer support systems. It is a very powerful tool for generating automated responses in customer support systems. It is a very powerful tool for generating automated responses in customer support systems. It is a very powerful tool for generating automated responses in customer support systems. It is a very powerful tool for generating automated responses in customer support systems. It is a very powerful tool for generating automated responses in customer support systems. It is a very powerful tool for generating automated responses in customer support systems. It is a very powerful tool for generating automated responses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_cdba6_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "      <td id=\"T_cdba6_row6_col0\" class=\"data row6 col0\" >Can you explain how Lamini allows me to customize models? What does it mean to customize a language model?</td>\n",
              "      <td id=\"T_cdba6_row6_col1\" class=\"data row6 col1\" > How does Lamini help me customize models? How does Lamini help me customize models? How does Lamini help me customize models? How does Lamini help me customize models? How does Lamini help me customize models? How does Lamini help me customize models? How does Lamini help me customize models? How does Lamini help me customize models? How does Lamini help me customize models? How does Lamini help me customize models? How does Lamini help me customize models? How does Lamini help me customize models? How does Lamini help me customize models? How does Lamini help me customize models? How does Lamini help me customize models? How does Lamini help me customize models? How does Lamini help me customize models? How does Lamini help me customize models? How does Lamini help me customize models? How does Lamini help me customize models? How does Lamini help me customize models? How does Lamini help me customize models? How does Lamini help me customize models? How does Lamini help me customize models? How does Lamini help me customize models? How does Lamini help</td>\n",
              "      <td id=\"T_cdba6_row6_col2\" class=\"data row6 col2\" >\n",
              "\n",
              "A:\n",
              "\n",
              "Lamini is a customization layer that is used to customize the LSTM model.\n",
              "\n",
              "Lamini is a customization layer that is used to customize the LSTM model.\n",
              "\n",
              "Lamini is a customization layer that is used to customize the LSTM model.\n",
              "\n",
              "Lamini is a customization layer that is used to customize the LSTM model.\n",
              "\n",
              "Lamini is a customization layer that is used to customize the LSTM model.\n",
              "\n",
              "Lamini is a customization layer that is used to customize the LSTM model.\n",
              "\n",
              "Lamini is a customization layer that is used to customize the LSTM model.\n",
              "\n",
              "Lamini is a customization layer that is used to customize the LSTM model.\n",
              "\n",
              "Lamini is a customization layer that is used to customize the LSTM model.\n",
              "\n",
              "Lamini is a customization layer that is used to customize the LSTM model.\n",
              "\n",
              "Lamini is a customization layer that is used to customize the LSTM model.\n",
              "\n",
              "Lamini is a customization layer that is used to customize the LSTM model.\n",
              "\n",
              "Lamini is a customization layer that is</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_cdba6_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "      <td id=\"T_cdba6_row7_col0\" class=\"data row7 col0\" >Does Lamini support model versioning and management to handle updates and maintenance?</td>\n",
              "      <td id=\"T_cdba6_row7_col1\" class=\"data row7 col1\" > Can you provide examples of how this can be done?</td>\n",
              "      <td id=\"T_cdba6_row7_col2\" class=\"data row7 col2\" >\n",
              "\n",
              "A:\n",
              "\n",
              "I think you are right.\n",
              "\n",
              "A:\n",
              "\n",
              "I think that the answer is yes.\n",
              "Lamini is a library that provides a lot of functionality to the modeler.\n",
              "Lamini is a library that provides a lot of functionality to the modeler.\n",
              "\n",
              "A:\n",
              "\n",
              "Lamini is a library that provides a lot of functionality to the modeler.\n",
              "\n",
              "I think that the answer is yes.\n",
              "\n",
              "A:\n",
              "\n",
              "I think that the answer is yes.\n",
              "\n",
              "A:\n",
              "\n",
              "I think that the answer is yes.\n",
              "\n",
              "Lamini is a library that provides a lot of functionality to the modeler.\n",
              "\n",
              "Lamini is a library that provides a lot of functionality to the modeler.\n",
              "\n",
              "A:\n",
              "\n",
              "I think that the answer is yes.\n",
              "\n",
              "A:\n",
              "\n",
              "Lamini is a library that provides a lot of functionality to the modeler.\n",
              "\n",
              "Lamini is a library that provides a lot of functionality to the modeler.\n",
              "\n",
              "A:\n",
              "\n",
              "I think that the answer is yes.\n",
              "\n",
              "A:\n",
              "\n",
              "I think that the answer is yes.\n",
              "\n",
              "A:\n",
              "\n",
              "I think that the answer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_cdba6_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "      <td id=\"T_cdba6_row8_col0\" class=\"data row8 col0\" >Can I use Lamini alongside other software development frameworks or tools, such as TensorFlow or PyTorch?</td>\n",
              "      <td id=\"T_cdba6_row8_col1\" class=\"data row8 col1\" >Lamini is a python library that can be used alongside other software development frameworks or tools. It is a powerful tool that can be used to help you build and run your own AI models. It can be used to help you build and run your own AI models, but it can also be used to help you build and run custom AI models. It can be used to help you build and run custom AI models, but it can also be used to help you build and run AI models that are more focused on specific tasks or domains. It can be used to help you build and run AI models that are more focused on specific tasks or domains, but it can also be used to help you build and run AI models that are more focused on specific tasks or domains. It can be used to help you build and run AI models that are more focused on specific tasks or domains, but it can also be used to help you build and run AI models that are more focused on specific tasks or domains. It can be used to help you build and run AI models that are more focused on specific tasks or domains, but it can also be used to help you build and run AI models that are more focused on specific tasks or domains. It can be used to help you build and run</td>\n",
              "      <td id=\"T_cdba6_row8_col2\" class=\"data row8 col2\" >\n",
              "\n",
              "A:\n",
              "\n",
              "I would recommend using TensorFlow. It's a great framework for machine learning and has a lot of great libraries.\n",
              "\n",
              "A:\n",
              "\n",
              "I would recommend using Tensorflow. It's a great framework for machine learning and has a lot of great libraries.\n",
              "\n",
              "I would recommend using Tensorflow. It's a great framework for machine learning and has a lot of great libraries.\n",
              "\n",
              "I would also recommend using Tensorflow. It's a great framework for machine learning and has a lot of great libraries.\n",
              "\n",
              "I would also recommend using Tensorflow. It's a great framework for machine learning and has a lot of great libraries.\n",
              "\n",
              "I would also recommend using Tensorflow. It's a great framework for machine learning and has a lot of great libraries.\n",
              "\n",
              "I would also recommend using Tensorflow. It's a great framework for machine learning and has a lot of great libraries.\n",
              "\n",
              "I would also recommend using Tensorflow. It's a great framework for machine learning and has a lot of great libraries.\n",
              "\n",
              "I would also recommend using Tensorflow. It's a great framework for machine learning and has a lot of great libraries.\n",
              "\n",
              "I would also recommend using Tensorflow. It's a great framework for machine</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_cdba6_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "      <td id=\"T_cdba6_row9_col0\" class=\"data row9 col0\" >Can Lamini be integrated into existing machine learning pipelines or workflows? How does it fit into the broader machine learning ecosystem?</td>\n",
              "      <td id=\"T_cdba6_row9_col1\" class=\"data row9 col1\" >Lamini is a python library that can be integrated into existing machine learning pipelines or workflows. It provides a python library wrapper around the Lamini library, which can be used to run a model in a machine learning environment. It also provides a python library wrapper around the Lamini library, which can be used to run a model in a workflow.</td>\n",
              "      <td id=\"T_cdba6_row9_col2\" class=\"data row9 col2\" >\n",
              "\n",
              "The answer is that it is not a new idea. It is a very old idea, and it is a very old idea that has been around for a long time.\n",
              "\n",
              "The idea is that you can use a machine learning model to learn a model of the world.\n",
              "\n",
              "The idea is that you can use a model of the world to learn a model of the world.\n",
              "\n",
              "The idea is that you can use a model of the world to learn a model of the world.\n",
              "\n",
              "The idea is that you can use a model of the world to learn a model of the world.\n",
              "\n",
              "The idea is that you can use a model of the world to learn a model of the world.\n",
              "\n",
              "The idea is that you can use a model of the world to learn a model of the world.\n",
              "\n",
              "The idea is that you can use a model of the world to learn a model of the world.\n",
              "\n",
              "The idea is that you can use a model of the world to learn a model of the world.\n",
              "\n",
              "The idea is that you can use a model of the world to learn a model of the world.\n",
              "\n",
              "The idea is that you can use a model of the world to learn a model of the world.\n",
              "</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    }
  ]
}
